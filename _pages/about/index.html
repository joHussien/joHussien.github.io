<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>I am a 1st year Ph.D. student at the Database Management Lab @University of Minnesota. I graduated 2023 from the American University in Cairo with Bachelors of Science in Computer Engineering and double minor in Maths and Arabic Studies. Link to your favorite <a href="http://reddit.com" rel="external nofollow noopener" target="_blank">subreddit</a>.</p> <p>I’m currently a Senior Researcher at <a href="http://www.msra.cn/" rel="external nofollow noopener" target="_blank">Microsoft Research Asia (MSRA)</a>, in a group managed by <a href="https://www.microsoft.com/en-us/research/people/xingx/" rel="external nofollow noopener" target="_blank">Xing Xie</a>. Before joining MSRA, I obtained my Ph.D. from Institute of Computing Technology, Chinese Academy of Sciences in June, 2019. My doctoral thesis was awarded the excellent Ph.D. thesis of Chinese Academy of Sciences. In 2018/04–2018/08, I was a visitor of Prof. <a href="https://cse.hkust.edu.hk/~qyang/" rel="external nofollow noopener" target="_blank">Qiang Yang</a>’s group at Hong Kong University of Science and Technology (HKUST). My work on transfer learning won the best paper awards in ICCSE 2018 and FTL-IJCAI 2019. In 2021, I published the textbook <a href="http://jd92.wang/tlbook" rel="external nofollow noopener" target="_blank">Introduction to Transfer Learning</a>, a hands-on introduction to transfer learning. In 2022, I was selected as one of the <a href="https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962c2a4" rel="external nofollow noopener" target="_blank">2022 AI 2000 Most Influential Scholars</a> by AMiner between 2012-2021 (ranked 49/2000). Four of my first-author papers are ranked by Google Scholar as <a href="https://zhuanlan.zhihu.com/p/421192644" rel="external nofollow noopener" target="_blank">highly-cited papers</a>. I gave tutorials at <a href="https://dgresearch.github.io/" rel="external nofollow noopener" target="_blank">IJCAI’22</a>, WSDM 2023, and KDD 2023.</p> <p><strong>Research interest:</strong> robust machine learning, out-of-distribution / domain generalization, transfer learning, semi-supervised learning, federated learning, and related applications such as activity recognition and computer vision. These days, I’m particularly interested in Large Language Models (LLMs) <a href="https://llm-eval.github.io/" rel="external nofollow noopener" target="_blank">evaluation</a> and <a href="https://llm-enhance.github.io/" rel="external nofollow noopener" target="_blank">robustness enhancement</a>. See this <a href="https://jd92.wang/research/" rel="external nofollow noopener" target="_blank">page</a> for more details. <em>Interested in <a href="https://zhuanlan.zhihu.com/p/102558267" rel="external nofollow noopener" target="_blank">internship</a> or collaboration? Contact me.</em></p> <p><strong>Announcement:</strong> I’m experimenting a new form of research collaboration. You can click <a href="https://forms.office.com/r/32Fs6uAjT6" rel="external nofollow noopener" target="_blank">here</a> if you are interested!</p> </body></html>